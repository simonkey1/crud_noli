#!/usr/bin/env python
"""
Script para diagnosticar problemas de p√©rdida de datos
"""
import os
import sys
import logging
from datetime import datetime

# Agregar el directorio ra√≠z al path para importar desde los m√≥dulos
script_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(script_dir)
sys.path.append(root_dir)

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)"

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(root_dir, 'logs', 'diagnostico.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def check_database_connection():
    """Verifica la conexi√≥n a la base de datos y sus detalles"""
    try:
        print(f"\nüì° Verificando conexi√≥n a la base de datos...")
        print(f"URL: {settings.DATABASE_URL.replace(settings.POSTGRES_PASSWORD, '********')}")
        print(f"Ambiente: {settings.ENVIRONMENT}")
        
        # Probar la conexi√≥n
        with engine.connect() as conn:
            result = conn.execute(text("SELECT version()")).fetchone()
            print(f"‚úÖ Conexi√≥n exitosa a PostgreSQL versi√≥n: {result[0]}")
            
            # Verificar tama√±o de la base de datos
            result = conn.execute(text("""
                SELECT pg_size_pretty(pg_database_size(current_database()))
            """)).fetchone()
            print(f"üìä Tama√±o de la base de datos: {result[0]}")
            
            # Verificar estad√≠sticas de tablas
            result = conn.execute(text("""
                SELECT 
                    relname as tabla, 
                    n_live_tup as registros
                FROM 
                    pg_stat_user_tables 
                ORDER BY 
                    n_live_tup DESC
            """)).fetchall()
            
            print("\nüìã Estad√≠sticas de tablas:")
            for row in result:
                print(f"   - {row[0]}: {row[1]} registros")
                
        return True
    except Exception as e:
        print(f"‚ùå Error al conectar a la base de datos: {str(e)}")
        return False

def check_rls_settings():
    """Verifica la configuraci√≥n de Row Level Security"""
    try:
        print("\nüîí Verificando configuraci√≥n de Row Level Security (RLS)...")
        
        with engine.connect() as conn:
            # Verificar tablas con RLS habilitado
            result = conn.execute(text("""
                SELECT 
                    tablename,
                    rowsecurity 
                FROM 
                    pg_tables
                WHERE 
                    schemaname = 'public'
                ORDER BY 
                    tablename
            """)).fetchall()
            
            print("\nüìã Estado de RLS por tabla:")
            for row in result:
                status = "‚úÖ Habilitado" if row[1] else "‚ùå Deshabilitado"
                print(f"   - {row[0]}: {status}")
            
            # Verificar pol√≠ticas de RLS
            result = conn.execute(text("""
                SELECT 
                    tablename,
                    policyname,
                    permissive,
                    cmd
                FROM 
                    pg_policies 
                WHERE 
                    schemaname = 'public'
                ORDER BY 
                    tablename, policyname
            """)).fetchall()
            
            print("\nüìã Pol√≠ticas de RLS configuradas:")
            for row in result:
                permissive = "Permisiva" if row[2] else "Restrictiva"
                print(f"   - {row[0]}: {row[1]} ({row[3]}, {permissive})")
                
        return True
    except Exception as e:
        print(f"‚ùå Error al verificar configuraci√≥n de RLS: {str(e)}")
        return False

def check_data_access():
    """Verifica el acceso a los datos seg√∫n las pol√≠ticas"""
    try:
        print("\nüîç Verificando acceso a los datos...")
        
        with Session(engine) as session:
            # Verificar categor√≠as
            categorias = session.exec(select(Categoria)).all()
            print(f"üìã Categor√≠as accesibles: {len(list(categorias))}")
            
            # Verificar productos
            productos = session.exec(select(Producto)).all()
            print(f"üìã Productos accesibles: {len(list(productos))}")
            
            # Mostrar ejemplos de datos
            if productos:
                print("\nüìù Ejemplos de productos accesibles:")
                for i, producto in enumerate(productos[:5]):
                    print(f"   {i+1}. {producto.nombre} (ID: {producto.id})")
            else:
                print("‚ùå No se encontraron productos accesibles")
                
        return True
    except Exception as e:
        print(f"‚ùå Error al verificar acceso a los datos: {str(e)}")
        return False

def check_render_config():
    """Verifica la configuraci√≥n de Render si es posible"""
    try:
        print("\nüñ•Ô∏è Verificando configuraci√≥n de Render...")
        render_service_id = os.environ.get("RENDER_SERVICE_ID")
        
        if render_service_id:
            print(f"‚úÖ Servicio Render detectado: {render_service_id}")
            
            # Verificar variables de entorno relevantes de Render
            render_vars = {k: v for k, v in os.environ.items() if k.startswith("RENDER_")}
            print(f"üìã Variables de entorno de Render detectadas: {len(render_vars)}")
            
            # Verificar configuraci√≥n de persistencia
            print("\n‚ö†Ô∏è Recomendaciones para Render:")
            print("   1. Aseg√∫rate de que los directorios que necesitan persistencia est√©n montados como vol√∫menes")
            print("   2. Verifica que la base de datos sea un servicio externo (no en el mismo contenedor)")
            print("   3. Revisa los logs de Render para ver si hay errores durante el despliegue")
        else:
            print("‚ÑπÔ∏è No se detect√≥ que esta aplicaci√≥n est√© corriendo en Render")
            
        return True
    except Exception as e:
        print(f"‚ùå Error al verificar configuraci√≥n de Render: {str(e)}")
        return False

def check_deployment_history():
    """Analiza el historial de despliegues si est√° disponible"""
    try:
        deploy_log = os.path.join(root_dir, 'logs', 'deploy_history.log')
        
        print("\nüìú Verificando historial de despliegues...")
        if os.path.exists(deploy_log):
            with open(deploy_log, 'r') as f:
                history = f.readlines()
                print(f"‚úÖ Historial de despliegues encontrado con {len(history)} entradas")
                if history:
                    print("üìã √öltimos despliegues:")
                    for line in history[-5:]:
                        print(f"   - {line.strip()}")
        else:
            print("‚ÑπÔ∏è No se encontr√≥ historial de despliegues")
            
            # Crear archivo de historial para futuros despliegues
            os.makedirs(os.path.dirname(deploy_log), exist_ok=True)
            with open(deploy_log, 'w') as f:
                f.write(f"{datetime.now().isoformat()} - Primer registro de diagn√≥stico\n")
            print("‚úÖ Se ha creado un archivo de historial para futuros despliegues")
            
        return True
    except Exception as e:
        print(f"‚ùå Error al verificar historial de despliegues: {str(e)}")
        return False

def create_watchdog():
    """Crea un script de vigilancia para detectar cambios en la base de datos"""
    try:
        print("\nüîç Creando script de vigilancia (watchdog)...")
        
        watchdog_path = os.path.join(script_dir, 'db_utils', 'data_watchdog.py')
        
        if not os.path.exists(os.path.dirname(watchdog_path)):
            os.makedirs(os.path.dirname(watchdog_path))
        
        watchdog_code = """#!/usr/bin/env python
# Script para monitorear cambios en la base de datos
import os
import sys
import time
import json
import logging
from datetime import datetime

# Agregar el directorio ra√≠z al path para importar desde los m√≥dulos
script_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(os.path.dirname(script_dir))
sys.path.append(root_dir)

from db.database import engine
from sqlmodel import Session, select
from sqlalchemy import text
from models.models import Producto, Categoria

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(root_dir, 'logs', 'data_watchdog.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def count_records():
    # Cuenta los registros en las principales tablas"""
    counts = {}
    try:
        with Session(engine) as session:
            # Contar productos
            productos_count = session.exec(select(Producto)).all()
            counts['productos'] = len(list(productos_count))
            
            # Contar categor√≠as
            categorias_count = session.exec(select(Categoria)).all()
            counts['categorias'] = len(list(categorias_count))
            
        return counts
    except Exception as e:
        logger.error(f"Error al contar registros: {str(e)}")
        return {'error': str(e)}

def save_snapshot(counts):
    """Guarda una instant√°nea de los conteos en un archivo JSON"""
    snapshots_dir = os.path.join(root_dir, 'logs', 'snapshots')
    if not os.path.exists(snapshots_dir):
        os.makedirs(snapshots_dir)
        
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    snapshot_file = os.path.join(snapshots_dir, f"snapshot_{timestamp}.json")
    
    data = {
        'timestamp': datetime.now().isoformat(),
        'counts': counts
    }
    
    with open(snapshot_file, 'w') as f:
        json.dump(data, f, indent=2)
        
    logger.info(f"Instant√°nea guardada en {snapshot_file}")
    
    # Tambi√©n actualizar el √∫ltimo estado
    latest_file = os.path.join(snapshots_dir, "latest_state.json")
    with open(latest_file, 'w') as f:
        json.dump(data, f, indent=2)
    
    return snapshot_file

def compare_with_previous():
    """Compara el estado actual con el anterior"""
    latest_file = os.path.join(root_dir, 'logs', 'snapshots', "latest_state.json")
    
    if not os.path.exists(latest_file):
        logger.info("No hay estado anterior para comparar")
        return None
        
    try:
        with open(latest_file, 'r') as f:
            previous_data = json.load(f)
            
        current_counts = count_records()
        
        changes = {}
        for key in set(previous_data['counts'].keys()).union(current_counts.keys()):
            prev_count = previous_data['counts'].get(key, 0)
            curr_count = current_counts.get(key, 0)
            
            if prev_count != curr_count:
                changes[key] = {
                    'before': prev_count,
                    'after': curr_count,
                    'diff': curr_count - prev_count
                }
                
        if changes:
            logger.warning(f"Cambios detectados en los datos: {changes}")
            
            # Registrar la alerta en un archivo especial
            alert_file = os.path.join(root_dir, 'logs', 'data_changes_alert.log')
            with open(alert_file, 'a') as f:
                f.write(f"{datetime.now().isoformat()} - Cambios detectados: {json.dumps(changes)}\\n")
                
        return changes
    except Exception as e:
        logger.error(f"Error al comparar estados: {str(e)}")
        return None

def run_monitor(interval=3600):
    """Ejecuta el monitor cada cierto intervalo (en segundos)"""
    logger.info(f"Iniciando monitoreo de datos cada {interval} segundos")
    
    try:
        # Tomar primera instant√°nea
        counts = count_records()
        save_snapshot(counts)
        logger.info(f"Estado inicial guardado: {counts}")
        
        while True:
            time.sleep(interval)
            logger.info("Tomando nueva instant√°nea...")
            
            counts = count_records()
            save_snapshot(counts)
            
            changes = compare_with_previous()
            if changes:
                logger.warning(f"‚ö†Ô∏è ALERTA: Se detectaron cambios en los datos: {changes}")
            else:
                logger.info("‚úÖ No se detectaron cambios en los datos")
    
    except KeyboardInterrupt:
        logger.info("Monitoreo detenido manualmente")
    except Exception as e:
        logger.error(f"Error en el monitoreo: {str(e)}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Monitor de cambios en datos')
    parser.add_argument('--interval', type=int, default=3600, 
                        help='Intervalo entre verificaciones (segundos)')
    parser.add_argument('--snapshot', action='store_true',
                        help='Tomar una instant√°nea y salir')
    
    args = parser.parse_args()
    
    if args.snapshot:
        counts = count_records()
        snapshot_file = save_snapshot(counts)
        print(f"Instant√°nea guardada en {snapshot_file}")
        print(f"Estado actual: {counts}")
    else:
        run_monitor(args.interval)
"""
        
        with open(watchdog_path, 'w') as f:
            f.write(watchdog_code)
            
        print(f"‚úÖ Script de vigilancia creado en: {watchdog_path}")
        print("""
    Para usar el script de vigilancia:
    1. Para tomar una instant√°nea del estado actual:
       python scripts/db_utils/data_watchdog.py --snapshot
       
    2. Para iniciar el monitor continuo (cada hora):
       python scripts/db_utils/data_watchdog.py
       
    3. Para personalizar el intervalo (ej: cada 10 minutos):
       python scripts/db_utils/data_watchdog.py --interval 600
    """)
            
        return True
    except Exception as e:
        print(f"‚ùå Error al crear script de vigilancia: {str(e)}")
        return False

def main():
    """Funci√≥n principal"""
    parser = argparse.ArgumentParser(description='Diagn√≥stico de problemas de p√©rdida de datos')
    parser.add_argument('--create-watchdog', action='store_true', help='Crear script de vigilancia')
    parser.add_argument('--check-rls', action='store_true', help='Verificar configuraci√≥n de Row Level Security')
    parser.add_argument('--all', action='store_true', help='Ejecutar todas las verificaciones')
    
    args = parser.parse_args()
    
    print("üîç DIAGN√ìSTICO DE PROBLEMAS DE P√âRDIDA DE DATOS")
    print("=" * 60)
    
    # Ejecutar verificaciones seg√∫n argumentos
    if args.all or not (args.create_watchdog or args.check_rls):
        check_database_connection()
        check_data_access()
        check_rls_settings()
        check_render_config()
        check_deployment_history()
        create_watchdog()
    else:
        if args.check_rls:
            check_rls_settings()
        
        if args.create_watchdog:
            create_watchdog()
    
    print("\n‚úÖ Diagn√≥stico completado")
    print("=" * 60)
    print("""
Recomendaciones para evitar p√©rdida de datos:
1. Configura backups autom√°ticos en Supabase o con el sistema existente
2. Verifica las pol√≠ticas de Row Level Security (RLS)
3. Usa el script de vigilancia para detectar cambios inesperados
4. En Render, configura vol√∫menes persistentes si necesitas almacenar archivos
5. Revisa los logs de despliegue despu√©s de cada actualizaci√≥n
    """)

if __name__ == "__main__":
    # Crear directorio de logs si no existe
    logs_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'logs')
    if not os.path.exists(logs_dir):
        os.makedirs(logs_dir)
        
    main()
